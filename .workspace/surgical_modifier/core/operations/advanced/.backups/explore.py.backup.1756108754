#!/usr/bin/env python3
"""
Explore operation implementation for Surgical Modifier v6.0
Advanced code analysis and exploration capabilities migrated from v5.3
"""
import os
import re
import ast
import json
import difflib
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

# Import from parent operations
try:
   from ..base_operation import (
       BaseOperation,
       OperationContext,
       OperationResult,
       OperationStatus,
       OperationType,
   )
except ImportError:
   try:
       from core.operations.base_operation import (
           BaseOperation,
           OperationContext, 
           OperationResult,
           OperationStatus,
           OperationType,
       )
   except ImportError:
       # Definiciones m√≠nimas para compatibilidad
       class BaseOperation:
           def __init__(self, operation_type, description):
               self.operation_type = operation_type
               self.description = description
       
       class OperationContext:
           def __init__(self, target_file=None):
               self.target_file = target_file
       
       class OperationResult:
           def __init__(self, success=True, message="", metadata=None, status=None):
               self.success = success
               self.message = message
               self.metadata = metadata or {}
               self.status = status
       
       class OperationStatus:
           SUCCESS = "success"
           FAILED = "failed"
       
       class OperationType:
           EXPLORE = "explore"

# Integration imports
try:
   from utils.logger import logger
   from utils.content_handler import content_handler
   from utils.path_resolver import path_resolver
   INTEGRATION_AVAILABLE = True
except ImportError:
   INTEGRATION_AVAILABLE = False
   logger = None

class UniversalPatternHelper:
   """MIGRADO v5.3: Asistente universal para encontrar patrones"""
   
   def __init__(self, file_content: str, file_path: str):
       self.content = file_content
       self.lines = file_content.split('\n')
       self.file_path = file_path
       self.file_type = self._detect_file_type()
       self.framework_context = self._detect_framework_context()
   
   def _detect_file_type(self) -> str:
       """Detectar tipo de archivo universal"""
       ext = os.path.splitext(self.file_path)[1].lower()
       
       type_mapping = {
           '.py': 'python',
           '.js': 'javascript', '.jsx': 'javascript',
           '.ts': 'typescript', '.tsx': 'typescript', 
           '.java': 'java',
           '.cpp': 'cpp', '.cc': 'cpp', '.cxx': 'cpp',
           '.c': 'c',
           '.cs': 'csharp',
           '.php': 'php',
           '.rb': 'ruby',
           '.go': 'go',
           '.rs': 'rust',
           '.swift': 'swift',
           '.kt': 'kotlin',
           '.scala': 'scala',
           '.html': 'markup',
           '.xml': 'markup',
           '.css': 'stylesheet',
           '.scss': 'stylesheet',
           '.json': 'config',
           '.yaml': 'config', '.yml': 'config',
           '.toml': 'config',
           '.sql': 'database',
           '.md': 'markdown',
           '.sh': 'bash',
       }
       
       return type_mapping.get(ext, 'generic')
   
   def _detect_framework_context(self) -> List[str]:
       """MIGRADO v5.3: Detectar contexto de frameworks universalmente"""
       frameworks = []
       content_lower = self.content.lower()
       
       # Frameworks Python
       if 'django' in content_lower or 'from django' in content_lower:
           frameworks.append('django')
       if 'flask' in content_lower or 'from flask' in content_lower:
           frameworks.append('flask')
       if 'fastapi' in content_lower or 'from fastapi' in content_lower:
           frameworks.append('fastapi')
       if 'sqlalchemy' in content_lower:
           frameworks.append('sqlalchemy')
       if 'pytest' in content_lower or '@pytest' in content_lower:
           frameworks.append('pytest')
       
       # Frameworks JavaScript/TypeScript
       if 'react' in content_lower or 'jsx' in content_lower:
           frameworks.append('react')
       if 'vue' in content_lower or '@vue' in content_lower:
           frameworks.append('vue')
       if 'angular' in content_lower or '@angular' in content_lower:
           frameworks.append('angular')
       if 'express' in content_lower:
           frameworks.append('express')
       
       return frameworks
   
   def find_flexible_pattern(self, target: str, similarity_threshold: float = 0.6) -> List[Dict]:
       """MIGRADO v5.3: B√∫squeda flexible universal"""
       results = []
       target_lower = target.lower()
       target_words = target_lower.split()
       
       for i, line in enumerate(self.lines, 1):
           line_clean = line.strip()
           if not line_clean or len(line_clean) < 3:
               continue
           
           # Similitud de secuencia
           similarity = difflib.SequenceMatcher(None, target_lower, line_clean.lower()).ratio()
           
           # Coincidencia de palabras clave
           word_matches = sum(1 for word in target_words if len(word) > 2 and word in line_clean.lower())
           word_similarity = word_matches / len(target_words) if target_words else 0
           
           # An√°lisis de estructura para c√≥digo
           structure_similarity = 0
           if self.file_type in ['python', 'javascript', 'typescript', 'java', 'cpp']:
               target_structure = self._extract_code_structure(target)
               line_structure = self._extract_code_structure(line_clean)
               if target_structure and line_structure:
                   structure_similarity = difflib.SequenceMatcher(None, target_structure, line_structure).ratio()
           
           # Combinar m√©tricas
           combined_score = (
               similarity * 0.4 +
               word_similarity * 0.4 + 
               structure_similarity * 0.2
           )
           
           if combined_score >= similarity_threshold:
               results.append({
                   'line_number': i,
                   'content': line_clean,
                   'similarity': combined_score,
                   'type': 'flexible_match',
                   'strategies': {
                       'sequence': similarity,
                       'words': word_similarity,
                       'structure': structure_similarity
                   }
               })
       
       results.sort(key=lambda x: x['similarity'], reverse=True)
       return results[:8]
   
   def _extract_code_structure(self, code: str) -> str:
       """MIGRADO v5.3: Extraer estructura de c√≥digo"""
       structure = re.sub(r'["\'].*?["\']', '""', code)
       structure = re.sub(r'//.*$|#.*$', '', structure)
       structure = re.sub(r'/\*.*?\*/', '', structure) 
       structure = re.sub(r'\s+', ' ', structure)
       return structure.strip()

class UniversalExplorer:
   """MIGRADO v5.3: Explorador universal mejorado para v6.0"""
   
   @staticmethod
   def show_file_structure(file_path: str, show_lines: bool = True, filter_type: str = 'smart') -> Dict[str, Any]:
       """MEJORADO v6.0: Mostrar estructura con retorno de datos"""
       try:
           with open(file_path, 'r', encoding='utf-8') as f:
               lines = f.readlines()
           
           helper = UniversalPatternHelper(''.join(lines), file_path)
           file_type = helper.file_type
           
           result = {
               'success': True,
               'file_path': file_path,
               'file_type': file_type,
               'total_lines': len(lines),
               'frameworks': helper.framework_context,
               'structure': [],
               'stats': {}
           }
           
           # Procesar l√≠neas importantes
           important_lines = UniversalExplorer._filter_important_lines(lines, file_type, filter_type)
           
           for line_info in important_lines:
               line_num, line_content, line_type = line_info
               result['structure'].append({
                   'line_number': line_num,
                   'content': line_content,
                   'type': line_type,
                   'icon': UniversalExplorer._get_line_icon(line_type)
               })
           
           # Estad√≠sticas
           result['stats'] = UniversalExplorer._get_file_stats(lines, file_type)
           
           return result
               
       except Exception as e:
           return {
               'success': False,
               'error': str(e),
               'file_path': file_path
           }
   
   @staticmethod
   def _filter_important_lines(lines: List[str], file_type: str, filter_type: str) -> List[Tuple[int, str, str]]:
       """MIGRADO v5.3: Filtrar l√≠neas importantes"""
       important = []
       
       for i, line in enumerate(lines, 1):
           line_clean = line.rstrip()
           if not line_clean or line_clean.isspace():
               continue
           
           line_importance = UniversalExplorer._classify_line_importance(line_clean, file_type)
           
           if filter_type == 'smart' and line_importance in ['high', 'medium']:
               important.append((i, line_clean, line_importance))
           elif filter_type == 'all':
               important.append((i, line_clean, line_importance))
           elif filter_type == 'high' and line_importance == 'high':
               important.append((i, line_clean, line_importance))
       
       return important
   
   @staticmethod
   def _classify_line_importance(line: str, file_type: str) -> str:
       """MIGRADO v5.3: Clasificar importancia universal"""
       line_lower = line.strip().lower()
       
       high_patterns = {
           'python': ['class ', 'def ', 'import ', 'from ', '@', 'if __name__'],
           'javascript': ['function ', 'class ', 'const ', 'export ', 'import ', '=>'],
           'typescript': ['interface ', 'type ', 'function ', 'class ', 'export ', 'import '],
           'java': ['public class', 'public interface', 'public enum', '@', 'import '],
           'cpp': ['class ', 'struct ', 'namespace ', '#include', 'template'],
           'generic': ['=', ':', '{', '}']
       }
       
       medium_patterns = {
           'python': ['return ', 'yield ', 'raise ', 'assert '],
           'javascript': ['return ', 'throw ', 'async ', 'await '],
           'typescript': ['return ', 'throw ', 'async ', 'await '],
           'java': ['return ', 'throw ', 'new ', 'super '],
           'cpp': ['return ', 'throw ', 'new ', 'delete '],
           'generic': ['(', ')', '[', ']']
       }
       
       file_high = high_patterns.get(file_type, high_patterns['generic'])
       file_medium = medium_patterns.get(file_type, medium_patterns['generic'])
       
       if any(pattern in line_lower for pattern in file_high):
           return 'high'
       elif any(pattern in line_lower for pattern in file_medium):
           return 'medium'
       else:
           return 'low'
   
   @staticmethod
   def _get_line_icon(line_type: str) -> str:
       """Obtener icono para tipo de l√≠nea"""
       icons = {
           'high': 'üî•',
           'medium': '‚ö°',
           'low': 'üìù'
       }
       return icons.get(line_type, 'üìÑ')
   
   @staticmethod
   def _get_file_stats(lines: List[str], file_type: str) -> Dict[str, int]:
       """MIGRADO v5.3: Estad√≠sticas del archivo"""
       stats = {
           'total_lines': len(lines),
           'non_empty_lines': len([l for l in lines if l.strip()]),
           'comment_lines': 0,
           'code_lines': 0
       }
       
       comment_patterns = {
           'python': ['#'],
           'javascript': ['//', '/*'],
           'typescript': ['//', '/*'],
           'java': ['//', '/*'],
           'cpp': ['//', '/*'],
           'generic': ['#', '//', '/*']
       }
       
       patterns = comment_patterns.get(file_type, comment_patterns['generic'])
       
       for line in lines:
           line_clean = line.strip()
           if line_clean:
               if any(line_clean.startswith(pattern) for pattern in patterns):
                   stats['comment_lines'] += 1
               else:
                   stats['code_lines'] += 1
       
       return stats
   
   @staticmethod
   def search_in_file(file_path: str, search_term: str, context_lines: int = 2, case_sensitive: bool = False) -> Dict[str, Any]:
       """MEJORADO v6.0: B√∫squeda con retorno de datos"""
       try:
           with open(file_path, 'r', encoding='utf-8') as f:
               lines = f.readlines()
           
           result = {
               'success': True,
               'file_path': file_path,
               'search_term': search_term,
               'case_sensitive': case_sensitive,
               'matches': []
           }
           
           for i, line in enumerate(lines):
               line_content = line.rstrip()
               search_target = search_term if case_sensitive else search_term.lower()
               line_target = line_content if case_sensitive else line_content.lower()
               
               if search_target in line_target:
                   # Obtener contexto
                   start = max(0, i - context_lines)
                   end = min(len(lines), i + context_lines + 1)
                   
                   context = []
                   for j in range(start, end):
                       context.append({
                           'line_number': j + 1,
                           'content': lines[j].rstrip(),
                           'is_match': j == i
                       })
                   
                   result['matches'].append({
                       'line_number': i + 1,
                       'content': line_content,
                       'context': context
                   })
           
           # B√∫squeda flexible si no hay matches exactos
           if not result['matches']:
               helper = UniversalPatternHelper(''.join(lines), file_path)
               similar = helper.find_flexible_pattern(search_term, 0.3)
               result['similar_matches'] = similar
           
           return result
               
       except Exception as e:
           return {
               'success': False,
               'error': str(e),
               'file_path': file_path
           }

class CodeQualityAnalyzer:
   """NUEVO v6.0: Analizador de calidad de c√≥digo avanzado"""
   
   def __init__(self, file_path: str, content: str):
       self.file_path = file_path
       self.content = content
       self.lines = content.split('\n')
       self.file_type = self._detect_file_type()
   
   def _detect_file_type(self) -> str:
       ext = os.path.splitext(self.file_path)[1].lower()
       type_mapping = {
           '.py': 'python', '.js': 'javascript', '.ts': 'typescript',
           '.java': 'java', '.cpp': 'cpp', '.c': 'c'
       }
       return type_mapping.get(ext, 'generic')
   
   def analyze_quality(self) -> Dict[str, Any]:
       """An√°lisis completo de calidad"""
       analysis = {
           'google_style_compliance': self._check_google_style(),
           'complexity_metrics': self._calculate_complexity(),
           'maintainability_score': 0,
           'issues_found': [],
           'recommendations': []
       }
       
       # Calcular score de mantenibilidad
       analysis['maintainability_score'] = self._calculate_maintainability(analysis)
       
       return analysis
   
   def _check_google_style(self) -> Dict[str, Any]:
       """Verificar cumplimiento Google Style Guide"""
       style = {
           'indentation_consistent': True,
           'line_length_ok': True,
           'naming_convention': True,
           'issues': []
       }
       
       if self.file_type == 'python':
           style.update(self._check_python_style())
       elif self.file_type in ['javascript', 'typescript']:
           style.update(self._check_js_style())
       
       return style
   
   def _check_python_style(self) -> Dict[str, Any]:
       """Verificar Python Google Style"""
       issues = []
       
       for i, line in enumerate(self.lines, 1):
           # Verificar longitud de l√≠nea
           if len(line) > 80:
               issues.append(f'L√≠nea {i}: Excede 80 caracteres ({len(line)})')
           
           # Verificar indentaci√≥n (4 espacios)
           if line.startswith('\t'):
               issues.append(f'L√≠nea {i}: Usar espacios en lugar de tabs')
           
           stripped = line.lstrip()
           if stripped and line != stripped:
               indent = len(line) - len(stripped)
               if indent % 4 != 0:
                   issues.append(f'L√≠nea {i}: Indentaci√≥n no m√∫ltiplo de 4')
       
       return {'python_style_issues': issues}
   
   def _check_js_style(self) -> Dict[str, Any]:
       """Verificar JavaScript/TypeScript Google Style"""
       issues = []
       
       for i, line in enumerate(self.lines, 1):
           # Verificar longitud de l√≠nea
           if len(line) > 80:
               issues.append(f'L√≠nea {i}: Excede 80 caracteres')
           
           # Verificar indentaci√≥n (2 espacios para JS)
           stripped = line.lstrip()
           if stripped and line != stripped:
               indent = len(line) - len(stripped)
               if indent % 2 != 0:
                   issues.append(f'L√≠nea {i}: Indentaci√≥n no m√∫ltiplo de 2')
       
       return {'js_style_issues': issues}
   
   def _calculate_complexity(self) -> Dict[str, int]:
       """Calcular m√©tricas de complejidad"""
       metrics = {
           'cyclomatic_complexity': 1,
           'nesting_depth': 0,
           'function_count': 0,
           'class_count': 0
       }
       
       if self.file_type == 'python':
           try:
               tree = ast.parse(self.content)
               
               # Contar funciones y clases
               for node in ast.walk(tree):
                   if isinstance(node, ast.FunctionDef):
                       metrics['function_count'] += 1
                   elif isinstance(node, ast.ClassDef):
                       metrics['class_count'] += 1
                   elif isinstance(node, (ast.If, ast.For, ast.While, ast.With)):
                       metrics['cyclomatic_complexity'] += 1
               
           except SyntaxError:
               pass
       
       # Calcular profundidad de anidamiento
       max_depth = 0
       
       for line in self.lines:
           stripped = line.lstrip()
           if stripped:
               indent_level = (len(line) - len(stripped)) // 2  # Asumiendo 2 espacios
               max_depth = max(max_depth, indent_level)
       
       metrics['nesting_depth'] = max_depth
       
       return metrics
   
   def _calculate_maintainability(self, analysis: Dict[str, Any]) -> int:
       """Calcular score de mantenibilidad (0-100)"""
       score = 100
       
       # Penalizar por problemas de estilo
       style_issues = len(analysis['google_style_compliance'].get('issues', []))
       score -= min(style_issues * 2, 30)
       
       # Penalizar por complejidad alta
       complexity = analysis['complexity_metrics']['cyclomatic_complexity']
       if complexity > 10:
           score -= (complexity - 10) * 3
       
       # Penalizar por anidamiento profundo
       nesting = analysis['complexity_metrics']['nesting_depth']
       if nesting > 4:
           score -= (nesting - 4) * 5
       
       return max(0, score)

class ExploreOperation(BaseOperation):
   """NUEVO v6.0: Operaci√≥n EXPLORE con arquitectura integrada"""
   
   def __init__(self):
       super().__init__(OperationType.EXPLORE, "Explore and analyze code files")
       self.explorer = UniversalExplorer()
   
   def execute(self, context: OperationContext) -> OperationResult:
       """Ejecutar an√°lisis de exploraci√≥n"""
       try:
           file_path = context.target_file
           
           if not os.path.exists(file_path):
               return self._error_result(f"File not found: {file_path}")
           
           # Leer contenido del archivo
           with open(file_path, 'r', encoding='utf-8') as f:
               content = f.read()
           
           # An√°lisis de estructura
           structure_result = self.explorer.show_file_structure(file_path)
           
           # An√°lisis de calidad
           quality_analyzer = CodeQualityAnalyzer(file_path, content)
           quality_result = quality_analyzer.analyze_quality()
           
           # An√°lisis de patrones
           helper = UniversalPatternHelper(content, file_path)
           
           # Compilar resultado completo
           analysis = {
               'file_info': {
                   'path': file_path,
                   'type': helper.file_type,
                   'frameworks': helper.framework_context,
                   'size': len(content),
                   'lines': len(content.split('\n'))
               },
               'structure_analysis': structure_result,
               'quality_analysis': quality_result,
               'patterns': {
                   'framework_patterns': [],
                   'important_lines': structure_result.get('structure', [])
               }
           }
           
           return OperationResult(    def can_rollback(self) -> bool:
        """Determinar si la operaci√≥n puede hacer rollback"""
        return False  # Explore es solo lectura, no necesita rollback
    
    def validate_context(self, context: OperationContext) -> bool:
        """Validar contexto de la operaci√≥n"""
        if not context or not hasattr(context, 'target_file'):
            return False
        
        target_file = context.target_file
        if not target_file or not isinstance(target_file, str):
            return False
            
        # Validar que sea un archivo v√°lido (puede no existir para CREATE)
        return len(target_file.strip()) > 0
    
               success=True,
               message=f"File analysis completed for {os.path.basename(file_path)}",
               metadata={'analysis': analysis}
           )
           
       except Exception as e:
           return self._error_result(f"Error during exploration: {str(e)}")
   
   def _error_result(self, error_msg: str) -> OperationResult:
       """Crear resultado de error"""
       return OperationResult(    def can_rollback(self) -> bool:
        """Determinar si la operaci√≥n puede hacer rollback"""
        return False  # Explore es solo lectura, no necesita rollback
    
    def validate_context(self, context: OperationContext) -> bool:
        """Validar contexto de la operaci√≥n"""
        if not context or not hasattr(context, 'target_file'):
            return False
        
        target_file = context.target_file
        if not target_file or not isinstance(target_file, str):
            return False
            
        # Validar que sea un archivo v√°lido (puede no existir para CREATE)
        return len(target_file.strip()) > 0
    
           success=False,
           message=error_msg,
           status=OperationStatus.FAILED
       )

# Funci√≥n principal para compatibilidad CLI
def explore_operation(file_path: str, analysis_type: str = "full", search_term: str = None) -> Dict[str, Any]:
   """Funci√≥n principal de exploraci√≥n con compatibilidad CLI"""
   
   try:
       explorer = UniversalExplorer()
       
       if not os.path.exists(file_path):
           return {
               'success': False,
               'error': f'File not found: {file_path}'
           }
       
       # Leer contenido
       with open(file_path, 'r', encoding='utf-8') as f:
           content = f.read()
       
       result = {
           'success': True,
           'file_path': file_path,
           'analysis_type': analysis_type
       }
       
       if search_term:
           # B√∫squeda espec√≠fica
           search_result = explorer.search_in_file(file_path, search_term)
           result['search_result'] = search_result
       else:
           # An√°lisis completo
           if analysis_type in ['structure', 'full']:
               structure = explorer.show_file_structure(file_path)
               result['structure'] = structure
           
           if analysis_type in ['quality', 'full']:
               analyzer = CodeQualityAnalyzer(file_path, content)
               quality = analyzer.analyze_quality()
               result['quality'] = quality
           
           if analysis_type in ['patterns', 'full']:
               helper = UniversalPatternHelper(content, file_path)
               result['patterns'] = {
                   'file_type': helper.file_type,
                   'frameworks': helper.framework_context
               }
       
       return result
       
   except Exception as e:
       return {
           'success': False,
           'error': str(e),
           'file_path': file_path
       }