#!/usr/bin/env python3
"""
üîß SURGICAL MODIFIER ULTIMATE v5.3 - HERRAMIENTA UNIVERSAL CORREGIDA
=======================================================================
"""

import ast  # Para verificaci√≥n de sintaxis Python
import difflib
import json
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Tuple
import os
import re
import subprocess
import sys
import tempfile
from datetime import datetime


class BackupManager:
    """Sistema de backup mejorado con limpieza autom√°tica"""

    def __init__(self, keep_successful_backups: bool = False, max_backups: int = 5):
        self.keep_successful_backups = keep_successful_backups
        self.max_backups = max_backups
        self.created_backups = []  # Track backups created in current operation

    def create_backup(self, file_path: str, backup_dir: str) -> str:
        """Crear backup con tracking para limpieza posterior"""
        os.makedirs(backup_dir, exist_ok=True)

        timestamp = int(datetime.now().timestamp())
        filename = os.path.basename(file_path)
        backup_filename = f"{filename}.backup.{timestamp}"
        backup_path = os.path.join(backup_dir, backup_filename)

        shutil.copy2(file_path, backup_path)

        # Track backup for potential cleanup
        self.created_backups.append(
            {
                "path": backup_path,
                "original_file": file_path,
                "timestamp": timestamp,
                "filename": backup_filename,
            }
        )

        ColorLogger.success(f"Backup creado: {os.path.relpath(backup_path)}")
        return backup_path

    def cleanup_successful_backups(self):
        """Limpiar backups despu√©s de operaci√≥n exitosa"""
        if not self.keep_successful_backups:
            cleaned_count = 0
            for backup_info in self.created_backups:
                try:
                    if os.path.exists(backup_info["path"]):
                        os.remove(backup_info["path"])
                        cleaned_count += 1
                        ColorLogger.info(
                            f"üßπ Backup limpiado: {backup_info['filename']}"
                        )
                except Exception as e:
                    ColorLogger.warning(f"No se pudo limpiar backup: {e}")

            if cleaned_count > 0:
                ColorLogger.success(
                    f"üßπ Sistema limpio: {cleaned_count} backup(s) eliminado(s) autom√°ticamente"
                )

            self.created_backups.clear()
        else:
            ColorLogger.info(
                f"üì¶ Backups conservados: {len(self.created_backups)} archivo(s)"
            )

    def restore_from_backup(self, backup_path: str, original_file: str):
        """Restaurar desde backup y conservar el backup"""
        try:
            shutil.copy2(backup_path, original_file)
            ColorLogger.info("üì¶ Backup restaurado por error")
            # NO eliminar backup cuando hay error - conservar para investigaci√≥n
        except Exception as e:
            ColorLogger.error(f"Error restaurando backup: {e}")

    def cleanup_old_backups(self, backup_dir: str):
        """Limpiar backups antiguos seg√∫n pol√≠tica de retenci√≥n"""
        if not os.path.exists(backup_dir):
            return

        try:
            # Obtener todos los archivos de backup
            backup_files = []
            for file in os.listdir(backup_dir):
                if ".backup." in file:
                    file_path = os.path.join(backup_dir, file)
                    if os.path.isfile(file_path):
                        # Extraer timestamp del nombre del archivo
                        try:
                            timestamp_str = file.split(".backup.")[-1]
                            timestamp = int(timestamp_str)
                            backup_files.append((file_path, timestamp))
                        except ValueError:
                            continue

            # Ordenar por timestamp (m√°s recientes primero)
            backup_files.sort(key=lambda x: x[1], reverse=True)

            # Conservar solo los √∫ltimos max_backups
            if len(backup_files) > self.max_backups:
                files_to_delete = backup_files[self.max_backups :]

                for file_path, timestamp in files_to_delete:
                    try:
                        os.remove(file_path)
                        ColorLogger.info(
                            f"üßπ Backup antiguo eliminado: {os.path.basename(file_path)}"
                        )
                    except Exception as e:
                        ColorLogger.warning(f"Error eliminando backup antiguo: {e}")

                if files_to_delete:
                    ColorLogger.info(
                        f"üßπ Limpieza de backups antiguos: {len(files_to_delete)} archivo(s) eliminado(s)"
                    )

        except Exception as e:
            ColorLogger.warning(f"Error en limpieza de backups antiguos: {e}")


class ColorLogger:
    """Sistema de logging con colores y estructura mejorado"""

    COLORS = {
        "red": "\033[31m",
        "green": "\033[32m",
        "yellow": "\033[33m",
        "blue": "\033[34m",
        "magenta": "\033[35m",
        "cyan": "\033[36m",
        "white": "\033[37m",
        "reset": "\033[0m",
        "bold": "\033[1m",
        "dim": "\033[2m",
    }

    @classmethod
    def success(cls, message: str):
        print(f"‚úÖ {message}")

    @classmethod
    def error(cls, message: str, suggestion: str = ""):
        print(f"{cls.COLORS['red']}‚ùå ERROR: {message}{cls.COLORS['reset']}")
        if suggestion:
            print(f"üîß Sugerencia: {suggestion}")

    @classmethod
    def warning(cls, message: str):
        print(f"{cls.COLORS['yellow']}‚ö†Ô∏è ADVERTENCIA: {message}{cls.COLORS['reset']}")

    @classmethod
    def info(cls, message: str):
        print(f"‚ÑπÔ∏è {message}")

    @classmethod
    def section(cls, title: str):
        print(f"\n=== üîß {title.upper()} ===")

    @classmethod
    def analyzing(cls, what: str):
        print(f"üîç ANALIZANDO: {what}")

    @classmethod
    def creating(cls, what: str):
        print(f"üìù CREANDO: {what}")

    @classmethod
    def preview(cls, title: str, content: str, max_lines: int = 5):
        """Mostrar preview de contenido"""
        print(f"\nüìã PREVIEW: {title}")
        lines = content.split("\n")
        for i, line in enumerate(lines[:max_lines]):
            print(f"   {i+1:2d}: {line}")
        if len(lines) > max_lines:
            print(f"   ... ({len(lines) - max_lines} l√≠neas m√°s)")

    @classmethod
    def diff(cls, title: str, before: str, after: str):
        """Mostrar diferencias visuales"""
        print(f"\nüìä DIFF: {title}")
        before_lines = before.split("\n")
        after_lines = after.split("\n")

        diff = list(
            difflib.unified_diff(
                before_lines,
                after_lines,
                fromfile="antes",
                tofile="despu√©s",
                lineterm="",
                n=3,
            )
        )

        for line in diff[:20]:  # Mostrar solo primeras 20 l√≠neas
            if line.startswith("+++") or line.startswith("---"):
                print(f"{cls.COLORS['blue']}{line}{cls.COLORS['reset']}")
            elif line.startswith("+"):
                print(f"{cls.COLORS['green']}{line}{cls.COLORS['reset']}")
            elif line.startswith("-"):
                print(f"{cls.COLORS['red']}{line}{cls.COLORS['reset']}")
            else:
                print(f"{cls.COLORS['dim']}{line}{cls.COLORS['reset']}")


class UniversalPatternHelper:
    """NUEVO v5.3: Asistente universal para encontrar patrones en cualquier proyecto"""

    def __init__(self, file_content: str, file_path: str):
        self.content = file_content
        self.lines = file_content.split("\n")
        self.file_path = file_path
        self.file_type = self._detect_file_type()
        self.framework_context = self._detect_framework_context()

    def _detect_file_type(self) -> str:
        """Detectar tipo de archivo universal"""
        ext = os.path.splitext(self.file_path)[1].lower()

        type_mapping = {
            ".py": "python",
            ".js": "javascript",
            ".ts": "typescript",
            ".jsx": "javascript",
            ".tsx": "typescript",
            ".java": "java",
            ".cpp": "cpp",
            ".c": "c",
            ".cs": "csharp",
            ".php": "php",
            ".rb": "ruby",
            ".go": "go",
            ".rs": "rust",
            ".swift": "swift",
            ".kt": "kotlin",
            ".scala": "scala",
            ".html": "markup",
            ".xml": "markup",
            ".css": "stylesheet",
            ".scss": "stylesheet",
            ".sass": "stylesheet",
            ".json": "config",
            ".yaml": "config",
            ".yml": "config",
            ".toml": "config",
            ".ini": "config",
            ".conf": "config",
            ".sh": "bash",
            ".bash": "bash",
            ".zsh": "bash",
            ".fish": "bash",
            ".sql": "database",
            ".md": "markdown",
            ".rst": "documentation",
            ".tex": "latex",
        }

        return type_mapping.get(ext, "generic")

    def _detect_framework_context(self) -> List[str]:
        """NUEVO v5.3: Detectar contexto de frameworks universalmente"""
        frameworks = []

        # An√°lisis universal de contenido
        content_lower = self.content.lower()

        # Frameworks Python
        if "django" in content_lower or "from django" in content_lower:
            frameworks.append("django")
        if "flask" in content_lower or "from flask" in content_lower:
            frameworks.append("flask")
        if "fastapi" in content_lower or "from fastapi" in content_lower:
            frameworks.append("fastapi")
        if "sqlalchemy" in content_lower or "column(" in content_lower:
            frameworks.append("sqlalchemy")
        if "pytest" in content_lower or "@pytest" in content_lower:
            frameworks.append("pytest")
        if "unittest" in content_lower or "class.*test" in content_lower:
            frameworks.append("unittest")

        # Frameworks JavaScript/TypeScript
        if "react" in content_lower or "jsx" in content_lower:
            frameworks.append("react")
        if "vue" in content_lower or "@vue" in content_lower:
            frameworks.append("vue")
        if "angular" in content_lower or "@angular" in content_lower:
            frameworks.append("angular")
        if "express" in content_lower or "app.get(" in content_lower:
            frameworks.append("express")
        if "jest" in content_lower or "describe(" in content_lower:
            frameworks.append("jest")
        # More specific mocha detection to avoid false positives in Python files
        if (
            "mocha" in content_lower
            and ("describe(" in content_lower or "it(" in content_lower)
        ) or (
            self.file_type in ["javascript", "typescript"] and "it(" in content_lower
        ):
            frameworks.append("mocha")

        # Frameworks Java
        if "spring" in content_lower or "@controller" in content_lower:
            frameworks.append("spring")
        if "junit" in content_lower or "@test" in content_lower:
            frameworks.append("junit")

        # Frameworks C#/.NET
        if "asp.net" in content_lower or "[httpget]" in content_lower:
            frameworks.append("aspnet")
        if "nunit" in content_lower or "[testmethod]" in content_lower:
            frameworks.append("nunit")

        # Frameworks gen√©ricos
        if (
            "docker" in content_lower
            or "from " in content_lower
            and ":" in content_lower
        ):
            frameworks.append("docker")
        if "kubernetes" in content_lower or "apiversion:" in content_lower:
            frameworks.append("kubernetes")

        return frameworks

    def find_flexible_pattern(
        self, target: str, similarity_threshold: float = 0.6
    ) -> List[Dict]:
        """NUEVO v5.3: B√∫squeda flexible universal con m√∫ltiples estrategias"""
        results = []
        target_lower = target.lower()
        target_words = target_lower.split()

        for i, line in enumerate(self.lines, 1):
            line_clean = line.strip()
            if not line_clean or len(line_clean) < 3:
                continue

            # Estrategia 1: Similitud de secuencia
            similarity = difflib.SequenceMatcher(
                None, target_lower, line_clean.lower()
            ).ratio()

            # Estrategia 2: Coincidencia de palabras clave
            word_matches = sum(
                1
                for word in target_words
                if len(word) > 2 and word in line_clean.lower()
            )
            word_similarity = word_matches / len(target_words) if target_words else 0

            # Estrategia 3: An√°lisis de estructura (para c√≥digo)
            structure_similarity = 0
            if self.file_type in [
                "python",
                "javascript",
                "typescript",
                "java",
                "cpp",
                "csharp",
            ]:
                # Buscar patrones estructurales similares
                target_structure = self._extract_code_structure(target)
                line_structure = self._extract_code_structure(line_clean)
                if target_structure and line_structure:
                    structure_similarity = difflib.SequenceMatcher(
                        None, target_structure, line_structure
                    ).ratio()

            # Combinar m√©tricas con pesos
            # Mejorar f√≥rmula: usar suma ponderada en lugar de max
            combined_score = (
                similarity * 0.4 + word_similarity * 0.4 + structure_similarity * 0.2
            )

            if combined_score >= similarity_threshold:
                results.append(
                    {
                        "line_number": i,
                        "content": line_clean,
                        "similarity": combined_score,
                        "type": "flexible_match",
                        "strategies": {
                            "sequence": similarity,
                            "words": word_similarity,
                            "structure": structure_similarity,
                        },
                    }
                )

        # Ordenar por similitud
        results.sort(key=lambda x: x["similarity"], reverse=True)
        return results[:8]  # Top 8 resultados

    def _extract_code_structure(self, code: str) -> str:
        """NUEVO v5.3: Extraer estructura de c√≥digo universal"""
        # Remover strings y comentarios para an√°lisis estructural
        structure = re.sub(r'["\'].*?["\']', '""', code)  # Remover strings
        structure = re.sub(r"//.*$|#.*$", "", structure)  # Remover comentarios de l√≠nea
        structure = re.sub(r"/\*.*?\*/", "", structure)  # Remover comentarios de bloque
        structure = re.sub(r"\s+", " ", structure)  # Normalizar espacios
        return structure.strip()

    def get_framework_specific_patterns(self) -> List[str]:
        """NUEVO v5.3: Obtener patrones espec√≠ficos del framework detectado"""
        patterns = []

        for framework in self.framework_context:
            if framework == "sqlalchemy":
                patterns.extend(self._get_sqlalchemy_patterns())
            elif framework == "pytest":
                patterns.extend(self._get_pytest_patterns())
            elif framework == "django":
                patterns.extend(self._get_django_patterns())
            elif framework == "react":
                patterns.extend(self._get_react_patterns())
            elif framework == "spring":
                patterns.extend(self._get_spring_patterns())
            # ... agregar m√°s frameworks seg√∫n necesidad

        # Si no hay frameworks espec√≠ficos, usar patrones gen√©ricos por tipo de archivo
        if not patterns:
            patterns = self._get_generic_patterns_by_type()

        return list(set(patterns))  # Eliminar duplicados

    def _get_sqlalchemy_patterns(self) -> List[str]:
        """Patrones espec√≠ficos de SQLAlchemy"""
        patterns = []
        for line in self.lines:
            line_clean = line.strip()
            if any(
                keyword in line_clean
                for keyword in ["Column(", "relationship(", "ForeignKey(", "Table("]
            ):
                patterns.append(line_clean)
        return patterns

    def _get_pytest_patterns(self) -> List[str]:
        """Patrones espec√≠ficos de pytest"""
        patterns = []
        for line in self.lines:
            line_clean = line.strip()
            if any(
                keyword in line_clean
                for keyword in ["@pytest", "def test_", "async def test_", "fixture"]
            ):
                patterns.append(line_clean)
        return patterns

    def _get_django_patterns(self) -> List[str]:
        """Patrones espec√≠ficos de Django"""
        patterns = []
        for line in self.lines:
            line_clean = line.strip()
            if any(
                keyword in line_clean
                for keyword in ["models.", "forms.", "views.", "urls.", "class.*View"]
            ):
                patterns.append(line_clean)
        return patterns

    def _get_react_patterns(self) -> List[str]:
        """Patrones espec√≠ficos de React"""
        patterns = []
        for line in self.lines:
            line_clean = line.strip()
            if any(
                keyword in line_clean
                for keyword in [
                    "useState",
                    "useEffect",
                    "function.*Component",
                    "export default",
                ]
            ):
                patterns.append(line_clean)
        return patterns

    def _get_spring_patterns(self) -> List[str]:
        """Patrones espec√≠ficos de Spring"""
        patterns = []
        for line in self.lines:
            line_clean = line.strip()
            if any(
                keyword in line_clean
                for keyword in [
                    "@Controller",
                    "@Service",
                    "@Repository",
                    "@Component",
                    "@RequestMapping",
                ]
            ):
                patterns.append(line_clean)
        return patterns

    def _get_generic_patterns_by_type(self) -> List[str]:
        """Patrones gen√©ricos seg√∫n tipo de archivo"""
        patterns = []

        if self.file_type == "python":
            keywords = ["def ", "class ", "import ", "from ", "if __name__"]
        elif self.file_type in ["javascript", "typescript"]:
            keywords = [
                "function ",
                "const ",
                "let ",
                "var ",
                "export ",
                "import ",
                "class ",
            ]
        elif self.file_type == "java":
            keywords = ["public class", "private ", "public ", "protected ", "import "]
        elif self.file_type == "cpp":
            keywords = [
                "class ",
                "struct ",
                "namespace ",
                "#include",
                "public:",
                "private:",
            ]
        elif self.file_type == "csharp":
            keywords = ["public class", "private ", "public ", "protected ", "using "]
        else:
            # Para tipos gen√©ricos, buscar l√≠neas que parecen definiciones
            keywords = ["=", ":", "{", "}", "(", ")"]

        for line in self.lines:
            line_clean = line.strip()
            if line_clean and any(keyword in line_clean for keyword in keywords):
                patterns.append(line_clean)

        return patterns[:15]  # Limitar resultados

    def suggest_pattern_fragments(self, target: str) -> List[str]:
        """NUEVO v5.3: Sugerir fragmentos de patr√≥n universales"""
        fragments = []

        if len(target) > 50:  # Patr√≥n muy largo
            # Extraer palabras clave importantes (universal)
            key_words = []

            # Filtrar palabras comunes por tipo de archivo
            common_words = self._get_common_words_by_type()

            for word in target.split():
                if (
                    len(word) > 3
                    and word.lower() not in common_words
                    and not word.isdigit()
                    and word.isalnum()
                ):
                    key_words.append(word)

            # Sugerir b√∫squedas por fragmentos
            for word in key_words[:4]:  # Top 4 palabras clave
                matching_lines = [
                    line.strip()
                    for line in self.lines
                    if word.lower() in line.lower() and len(line.strip()) > 10
                ]
                fragments.extend(matching_lines[:2])  # Max 2 por palabra

        return list(set(fragments))  # Eliminar duplicados

    def _get_common_words_by_type(self) -> List[str]:
        """Obtener palabras comunes seg√∫n el tipo de archivo"""
        common_by_type = {
            "python": [
                "def",
                "class",
                "self",
                "none",
                "true",
                "false",
                "and",
                "or",
                "not",
                "with",
                "as",
            ],
            "javascript": [
                "function",
                "const",
                "let",
                "var",
                "null",
                "undefined",
                "true",
                "false",
                "this",
            ],
            "typescript": [
                "function",
                "const",
                "let",
                "var",
                "null",
                "undefined",
                "true",
                "false",
                "this",
                "interface",
                "type",
            ],
            "java": [
                "public",
                "private",
                "protected",
                "static",
                "final",
                "class",
                "interface",
                "null",
                "true",
                "false",
            ],
            "cpp": [
                "public",
                "private",
                "protected",
                "class",
                "struct",
                "namespace",
                "using",
                "include",
            ],
            "generic": [
                "the",
                "and",
                "or",
                "not",
                "with",
                "for",
                "in",
                "on",
                "at",
                "to",
                "from",
            ],
        }

        return common_by_type.get(self.file_type, common_by_type["generic"])


class UniversalExplorer:
    """NUEVO v5.3: Explorador universal para cualquier tipo de archivo"""

    @staticmethod
    def show_file_structure(
        file_path: str, show_lines: bool = True, filter_type: str = "smart"
    ) -> None:
        """Mostrar estructura universal del archivo"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            # Usar UniversalPatternHelper para detecci√≥n consistente
            helper = UniversalPatternHelper("", file_path)
            file_type = helper.file_type

            print(f"\nüìã ESTRUCTURA DE ARCHIVO: {os.path.basename(file_path)}")
            print(f"üìä Total l√≠neas: {len(lines)} | Tipo: {file_type}")
            print("=" * 60)

            important_lines = UniversalExplorer._filter_important_lines(
                lines, file_type, filter_type
            )

            for line_info in important_lines:
                line_num, line_content, line_type = line_info
                icon = UniversalExplorer._get_line_icon(line_type)

                if show_lines:
                    print(f"{line_num:3d}: {icon} {line_content}")
                else:
                    truncated = (
                        line_content[:70] + "..."
                        if len(line_content) > 70
                        else line_content
                    )
                    print(f"{line_num:3d}: {icon} {truncated}")

            # Estad√≠sticas
            print(f"\nüìä ESTAD√çSTICAS:")
            stats = UniversalExplorer._get_file_stats(lines, file_type)
            for stat, value in stats.items():
                print(f"   {stat}: {value}")

        except Exception as e:
            print(f"‚ùå Error explorando archivo: {e}")

    @staticmethod
    def _filter_important_lines(
        lines: List[str], file_type: str, filter_type: str
    ) -> List[Tuple[int, str, str]]:
        """Filtrar l√≠neas importantes seg√∫n el tipo de archivo"""
        important = []

        for i, line in enumerate(lines, 1):
            line_clean = line.rstrip()
            if not line_clean or line_clean.isspace():
                continue

            line_importance = UniversalExplorer._classify_line_importance(
                line_clean, file_type
            )

            if filter_type == "smart" and line_importance in ["high", "medium"]:
                important.append((i, line_clean, line_importance))
            elif filter_type == "all":
                important.append((i, line_clean, line_importance))
            elif filter_type == "high" and line_importance == "high":
                important.append((i, line_clean, line_importance))

        return important

    @staticmethod
    def _classify_line_importance(line: str, file_type: str) -> str:
        """Clasificar importancia de l√≠nea universal"""
        line_lower = line.strip().lower()

        # Patrones universales de alta importancia
        high_patterns = {
            "python": ["class ", "def ", "import ", "from ", "@", "if __name__"],
            "javascript": ["function ", "class ", "const ", "export ", "import ", "=>"],
            "typescript": [
                "interface ",
                "type ",
                "function ",
                "class ",
                "export ",
                "import ",
            ],
            "java": ["public class", "public interface", "public enum", "@", "import "],
            "cpp": ["class ", "struct ", "namespace ", "#include", "template"],
            "csharp": [
                "public class",
                "public interface",
                "public enum",
                "using ",
                "[",
            ],
            "generic": ["=", ":", "{", "}"],
        }

        # Patrones universales de importancia media
        medium_patterns = {
            "python": [
                "return ",
                "yield ",
                "raise ",
                "assert ",
                "global ",
                "nonlocal ",
            ],
            "javascript": ["return ", "throw ", "async ", "await ", "var ", "let "],
            "typescript": ["return ", "throw ", "async ", "await ", "var ", "let "],
            "java": ["return ", "throw ", "new ", "super ", "this "],
            "cpp": ["return ", "throw ", "new ", "delete ", "virtual "],
            "csharp": ["return ", "throw ", "new ", "base ", "this "],
            "generic": ["(", ")", "[", "]"],
        }

        file_high = high_patterns.get(file_type, high_patterns["generic"])
        file_medium = medium_patterns.get(file_type, medium_patterns["generic"])

        # Verificar importancia
        if any(pattern in line_lower for pattern in file_high):
            return "high"
        elif any(pattern in line_lower for pattern in file_medium):
            return "medium"
        else:
            return "low"

    @staticmethod
    def _get_line_icon(line_type: str) -> str:
        """Obtener icono para tipo de l√≠nea"""
        icons = {"high": "üî•", "medium": "‚ö°", "low": "üìù"}
        return icons.get(line_type, "üìÑ")

    @staticmethod
    def _get_file_stats(lines: List[str], file_type: str) -> Dict[str, int]:
        """Obtener estad√≠sticas del archivo"""
        stats = {
            "Total l√≠neas": len(lines),
            "L√≠neas no vac√≠as": len([l for l in lines if l.strip()]),
            "L√≠neas de comentarios": 0,
            "L√≠neas de c√≥digo": 0,
        }

        # Detectar comentarios seg√∫n tipo de archivo
        comment_patterns = {
            "python": ["#"],
            "javascript": ["//", "/*"],
            "typescript": ["//", "/*"],
            "java": ["//", "/*"],
            "cpp": ["//", "/*"],
            "csharp": ["//", "/*"],
            "generic": ["#", "//", "/*"],
        }

        patterns = comment_patterns.get(file_type, comment_patterns["generic"])

        for line in lines:
            line_clean = line.strip()
            if line_clean:
                if any(line_clean.startswith(pattern) for pattern in patterns):
                    stats["L√≠neas de comentarios"] += 1
                else:
                    stats["L√≠neas de c√≥digo"] += 1

        return stats

    @staticmethod
    def search_in_file(
        file_path: str,
        search_term: str,
        context_lines: int = 2,
        case_sensitive: bool = False,
    ) -> None:
        """B√∫squeda universal en archivo con contexto"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            print(f"\nüîç B√öSQUEDA: '{search_term}' en {os.path.basename(file_path)}")
            print(
                f"üéØ Modo: {'Sensible a may√∫sculas' if case_sensitive else 'Insensible a may√∫sculas'}"
            )
            print("=" * 60)

            matches_found = 0

            for i, line in enumerate(lines):
                line_content = line.rstrip()
                search_target = search_term if case_sensitive else search_term.lower()
                line_target = line_content if case_sensitive else line_content.lower()

                if search_target in line_target:
                    matches_found += 1

                    # Mostrar contexto
                    start = max(0, i - context_lines)
                    end = min(len(lines), i + context_lines + 1)

                    print(f"\nüìç Coincidencia #{matches_found} - L√≠nea {i+1}:")

                    for j in range(start, end):
                        line_to_show = lines[j].rstrip()
                        if j == i:
                            # Resaltar l√≠nea con coincidencia
                            print(f">>> {j+1:3d}: {line_to_show}")
                        else:
                            print(f"    {j+1:3d}: {line_to_show}")

            if matches_found == 0:
                print(f"‚ùå No se encontraron coincidencias para '{search_term}'")

                # Sugerir b√∫squedas similares
                helper = UniversalPatternHelper("\n".join(lines), file_path)
                similar = helper.find_flexible_pattern(search_term, 0.3)
                if similar:
                    print(f"\nüí° ¬øQuiz√°s buscabas algo similar?")
                    for match in similar[:3]:
                        print(f"   L√≠nea {match['line_number']}: {match['content']}")
            else:
                print(f"\n‚úÖ Se encontraron {matches_found} coincidencias")

        except Exception as e:
            print(f"‚ùå Error buscando en archivo: {e}")


class ContentHandler:
    """Manejo inteligente de contenido con correcciones v5.3"""

    def __init__(self, content: str, file_path: str = "", operation: str = ""):
        self.original_content = content
        self.file_path = file_path
        self.operation = operation
        self.content_type = self._detect_content_type()
        self.is_problematic = self._detect_problematic_content()
        self.handling_strategy = self._determine_strategy()

    def _detect_content_type(self) -> str:
        """Detectar tipo de contenido basado en archivo y contenido"""

        # Detecci√≥n por extensi√≥n de archivo
        if self.file_path:
            ext = os.path.splitext(self.file_path)[1].lower()
            type_mapping = {
                ".py": "python",
                ".js": "javascript",
                ".jsx": "javascript",
                ".ts": "typescript",
                ".tsx": "typescript",
                ".java": "java",
                ".cpp": "cpp",
                ".cc": "cpp",
                ".cxx": "cpp",
                ".c": "c",
                ".cs": "csharp",
                ".php": "php",
                ".rb": "ruby",
                ".go": "go",
                ".rs": "rust",
                ".swift": "swift",
                ".kt": "kotlin",
                ".scala": "scala",
                ".sh": "bash",
                ".bash": "bash",
                ".html": "markup",
                ".xml": "markup",
                ".css": "stylesheet",
                ".scss": "stylesheet",
                ".json": "config",
                ".yaml": "config",
                ".yml": "config",
                ".sql": "database",
            }

            if ext in type_mapping:
                return type_mapping[ext]

        # Detecci√≥n por contenido (universal)
        content_lower = self.original_content.lower()

        # Indicadores por lenguaje
        if any(
            indicator in content_lower
            for indicator in ["def ", "class ", "import ", "from ", "__name__"]
        ):
            return "python"
        elif any(
            indicator in content_lower
            for indicator in [
                "function ",
                "const ",
                "let ",
                "var ",
                "=>",
                "console.log",
            ]
        ):
            return "javascript"
        elif any(
            indicator in content_lower
            for indicator in ["interface ", "type ", "export ", "import "]
        ):
            return "typescript"
        elif any(
            indicator in content_lower
            for indicator in ["public class", "public static", "import java"]
        ):
            return "java"
        elif any(
            indicator in content_lower
            for indicator in ["#include", "namespace ", "std::"]
        ):
            return "cpp"
        elif any(
            indicator in content_lower
            for indicator in ["using system", "public class", "namespace "]
        ):
            return "csharp"
        elif any(
            indicator in content_lower
            for indicator in ["#!/bin/bash", "echo ", "if [", "${", "then", "fi"]
        ):
            return "bash"
        else:
            return "generic"

    def _detect_problematic_content(self) -> bool:
        """Detectar si el contenido es problem√°tico para bash (universal)"""

        # Para lenguajes de programaci√≥n modernos, ser m√°s permisivo
        if self.content_type in [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "csharp",
        ]:
            problematic_indicators = [
                # Solo contenido extremadamente complejo
                len(self.original_content.split("\n")) > 20,
                len(self.original_content) > 3000,
                # Backticks con comandos bash reales
                "`" in self.original_content
                and any(
                    cmd in self.original_content
                    for cmd in ["ls", "cat", "grep", "find"]
                ),
                # Variables bash complejas
                "${" in self.original_content
                and "bash" in self.original_content.lower(),
            ]
        else:
            # Para otros tipos, usar detecci√≥n m√°s estricta
            problematic_indicators = [
                len(self.original_content.split("\n")) > 8,
                '"' in self.original_content and "'" in self.original_content,
                "`" in self.original_content,
                "$" in self.original_content and "{" in self.original_content,
                self.original_content.count('"') % 2 != 0,
                self.original_content.count("'") % 2 != 0,
                "\\" in self.original_content,
                len(self.original_content) > 1000,
            ]

        return any(problematic_indicators)

    def _determine_strategy(self) -> str:
        """Determinar estrategia de manejo inteligente universal"""

        # NUEVA L√ìGICA v5.3: M√°s inteligente para contenido universal
        if self.content_type in [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "csharp",
        ]:
            ColorLogger.info(
                f"Modo RAW v5.3 activado para contenido {self.content_type}"
            )
            return "raw_mode_v3"

        if not self.is_problematic:
            return "direct"
        elif len(self.original_content.split("\n")) > 20:
            return "temp_file"
        elif "`" in self.original_content and any(
            cmd in self.original_content for cmd in ["ls", "cat", "grep"]
        ):
            return "temp_file"
        elif '"' in self.original_content or "'" in self.original_content:
            return "smart_escape_v3"
        else:
            return "escape_special_v3"

    def get_safe_content(self) -> Tuple[str, Optional[str]]:
        """Obtener contenido seguro con mejoras v5.3"""

        if self.handling_strategy == "raw_mode_v3":
            # NUEVO v5.3: Modo RAW universal mejorado
            processed_content = self._process_multiline_content_v3()
            ColorLogger.info("Usando modo RAW v5.3 - procesamiento universal mejorado")
            return processed_content, None

        elif self.handling_strategy == "direct":
            return self.original_content, None

        elif self.handling_strategy == "temp_file":
            temp_file = self._create_temp_file()
            return f"@TEMP_FILE:{temp_file}", temp_file

        elif self.handling_strategy == "smart_escape_v3":
            escaped = self._smart_escape_v3()
            return escaped, None

        elif self.handling_strategy == "escape_special_v3":
            escaped = self._escape_special_v3()
            return escaped, None

        else:
            # Fallback mejorado
            temp_file = self._create_temp_file()
            return f"@TEMP_FILE:{temp_file}", temp_file

    def _process_multiline_content_v3(self) -> str:
        """NUEVO v5.3: Procesar contenido multi-l√≠nea universal"""
        content = self.original_content

        # Si el contenido contiene \n literal, convertirlos a saltos de l√≠nea reales
        if "\\n" in content:
            # Solo convertir \n que no est√°n ya escapados
            content = re.sub(r"(?<!\\)\\n", "\n", content)
            ColorLogger.info("Convertidos \\n literales a saltos de l√≠nea reales")

        # Procesamiento adicional para diferentes tipos de contenido
        if self.content_type == "python":
            # Preservar indentaci√≥n Python
            content = self._preserve_python_indentation(content)
        elif self.content_type in ["javascript", "typescript"]:
            # Preservar estructura de bloques JavaScript/TypeScript
            content = self._preserve_js_structure(content)

        return content

    def _preserve_python_indentation(self, content: str) -> str:
        """Preservar indentaci√≥n Python"""
        lines = content.split("\n")
        preserved_lines = []

        for line in lines:
            # Preservar indentaci√≥n existente
            if line.strip():
                preserved_lines.append(line)
            else:
                preserved_lines.append("")

        return "\n".join(preserved_lines)

    def _preserve_js_structure(self, content: str) -> str:
        """Preservar estructura JavaScript/TypeScript"""
        # Manejar template literals y arrow functions
        content = re.sub(r"`([^`]*)`", r"`\1`", content)  # Preservar template literals
        return content

    def _smart_escape_v3(self) -> str:
        """NUEVO v5.3: Escape inteligente universal mejorado"""
        content = self.original_content

        # Escape universal m√°s inteligente
        if self.content_type in [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "csharp",
        ]:
            # Solo escapar caracteres cr√≠ticos para bash
            bash_critical = ["!", "$`", "$(", "&&", "||"]
            for chars in bash_critical:
                if chars in content:
                    # Usar temp file para casos realmente problem√°ticos
                    return f"@TEMP_FILE:{self._create_temp_file()}"

            # Para casos simples, escape m√≠nimo
            content = content.replace('"', '\\"')
        else:
            # Para otros tipos, escape m√°s completo pero inteligente
            content = content.replace("\\", "\\\\")  # Escapar backslashes primero
            content = content.replace('"', '\\"')  # Escapar comillas dobles
            if "'" in content and '"' in content:
                content = content.replace("'", "\\'")

        return content

    def _escape_special_v3(self) -> str:
        """NUEVO v5.3: Escape de caracteres especiales universal"""
        content = self.original_content

        # Solo escapar caracteres realmente problem√°ticos universalmente
        critical_chars = ["$`", "$(", "!", "&&", "||"]

        for chars in critical_chars:
            if chars in content:
                # Para casos cr√≠ticos, usar temp file
                return f"@TEMP_FILE:{self._create_temp_file()}"

        # Para otros casos, escape selectivo universal
        safe_chars = ["`"]  # Solo backticks simples
        for char in safe_chars:
            if char in content:
                content = content.replace(char, f"\\{char}")

        return content

    def _create_temp_file(self) -> str:
        """Crear archivo temporal con el contenido"""
        processed_content = self._process_multiline_content_v3()
        with tempfile.NamedTemporaryFile(
            mode="w", delete=False, suffix=".tmp", encoding="utf-8"
        ) as f:
            f.write(processed_content)
            return f.name


class ProjectContext:
    """Detecci√≥n y gesti√≥n del contexto del proyecto universal"""

    def __init__(self):
        self.current_dir = os.getcwd()
        self.context = self._detect_context()
        self.project_root = self._find_project_root()
        self.structure = self._analyze_project_structure()

    def _detect_context(self) -> str:
        """Detectar contexto universal desde directorio"""
        cwd = self.current_dir.lower()

        # Patrones universales de estructura de proyecto
        if any(pattern in cwd for pattern in ["/backend", "/server", "/api"]):
            return "backend"
        elif any(pattern in cwd for pattern in ["/frontend", "/client", "/ui", "/web"]):
            return "frontend"
        elif any(pattern in cwd for pattern in ["/mobile", "/app", "/android", "/ios"]):
            return "mobile"
        elif any(pattern in cwd for pattern in ["/tests", "/test", "/spec"]):
            return "testing"
        elif any(pattern in cwd for pattern in ["/docs", "/documentation"]):
            return "documentation"
        elif any(pattern in cwd for pattern in ["/scripts", "/tools", "/bin"]):
            return "scripts"
        else:
            return "root"

    def _find_project_root(self) -> str:
        """Encontrar ra√≠z del proyecto universal"""
        current = Path(self.current_dir)

        # Indicadores universales de ra√≠z de proyecto
        project_indicators = [
            # JavaScript/Node.js
            "package.json",
            "yarn.lock",
            "package-lock.json",
            # Python
            "requirements.txt",
            "pyproject.toml",
            "setup.py",
            "Pipfile",
            # Java
            "pom.xml",
            "build.gradle",
            "gradle.properties",
            # .NET
            "*.sln",
            "*.csproj",
            "global.json",
            # Go
            "go.mod",
            "go.sum",
            # Rust
            "Cargo.toml",
            "Cargo.lock",
            # Ruby
            "Gemfile",
            "Gemfile.lock",
            # PHP
            "composer.json",
            "composer.lock",
            # Universal
            ".git",
            ".gitignore",
            "README.md",
            "README.rst",
            "Dockerfile",
            "docker-compose.yml",
            "Makefile",
            "CMakeLists.txt",
            ".workspace",
        ]

        # Buscar hacia arriba hasta encontrar indicadores
        for parent in [current] + list(current.parents):
            for indicator in project_indicators:
                if "*" in indicator:
                    # Buscar patrones con wildcards
                    pattern = indicator.replace("*", "")
                    try:
                        if any(
                            f.name.endswith(pattern)
                            for f in parent.iterdir()
                            if f.is_file()
                        ):
                            return str(parent)
                    except (PermissionError, OSError):
                        continue
                else:
                    if (parent / indicator).exists():
                        return str(parent)

        return self.current_dir

    def _analyze_project_structure(self) -> Dict[str, Any]:
        """Analizar estructura del proyecto universal"""
        root = Path(self.project_root)

        structure = {
            "project_type": self._determine_project_type(root),
            "has_backend": self._has_directory_pattern(
                root, ["backend", "server", "api"]
            ),
            "has_frontend": self._has_directory_pattern(
                root, ["frontend", "client", "ui", "web"]
            ),
            "has_mobile": self._has_directory_pattern(
                root, ["mobile", "app", "android", "ios"]
            ),
            "has_tests": self._has_directory_pattern(
                root, ["tests", "test", "spec", "__tests__"]
            ),
            "has_docs": self._has_directory_pattern(
                root, ["docs", "documentation", "doc"]
            ),
            "has_scripts": self._has_directory_pattern(
                root, ["scripts", "tools", "bin"]
            ),
            "languages": self._detect_languages(root),
            "frameworks": self._detect_frameworks(root),
        }

        return structure

    def _has_directory_pattern(self, root: Path, patterns: List[str]) -> bool:
        """Verificar si existe alg√∫n directorio con los patrones dados"""
        try:
            for item in root.iterdir():
                if item.is_dir() and any(
                    pattern in item.name.lower() for pattern in patterns
                ):
                    return True
        except (PermissionError, OSError):
            pass
        return False

    def _determine_project_type(self, root: Path) -> str:
        """Determinar tipo de proyecto universal"""
        indicators = {
            "web_fullstack": ["package.json", "requirements.txt"],
            "web_frontend": ["package.json", "yarn.lock"],
            "python": ["requirements.txt", "pyproject.toml", "setup.py"],
            "java": ["pom.xml", "build.gradle"],
            "dotnet": ["*.sln", "*.csproj"],
            "go": ["go.mod"],
            "rust": ["Cargo.toml"],
            "ruby": ["Gemfile"],
            "php": ["composer.json"],
            "cpp": ["CMakeLists.txt", "Makefile"],
            "docker": ["Dockerfile", "docker-compose.yml"],
            "mobile": ["android", "ios", "App.js", "App.tsx"],
        }
        
        detected_types = []
        for project_type, files in indicators.items():
            for file_pattern in files:
                if "*" in file_pattern:
                    pattern = file_pattern.replace("*", "")
                    try:
                        if any(f.name.endswith(pattern) for f in root.iterdir() if f.is_file()):
                            detected_types.append(project_type)
                            break
                    except (PermissionError, OSError):
                        continue
                else:
                    if (root / file_pattern).exists():
                        detected_types.append(project_type)
                        break
        
        if len(detected_types) > 1:
            return "polyglot"
        elif detected_types:
            return detected_types[0]
        else:
            return "unknown"

    def _detect_languages(self, root: Path) -> List[str]:
        """Detectar lenguajes de programaci√≥n en el proyecto"""
        languages = set()

        extension_mapping = {
            ".py": "python",
            ".js": "javascript",
            ".jsx": "javascript",
            ".ts": "typescript",
            ".tsx": "typescript",
            ".java": "java",
            ".cpp": "cpp",
            ".cc": "cpp",
            ".cxx": "cpp",
            ".c": "c",
            ".cs": "csharp",
            ".php": "php",
            ".rb": "ruby",
            ".go": "go",
            ".rs": "rust",
            ".swift": "swift",
            ".kt": "kotlin",
            ".scala": "scala",
            ".html": "html",
            ".css": "css",
            ".scss": "css",
            ".sass": "css",
            ".sql": "sql",
        }

        try:
            for file_path in root.rglob("*"):
                if file_path.is_file():
                    ext = file_path.suffix.lower()
                    if ext in extension_mapping:
                        languages.add(extension_mapping[ext])
        except (PermissionError, OSError):
            pass

        return list(languages)

    def _detect_frameworks(self, root: Path) -> List[str]:
        """Detectar frameworks utilizados en el proyecto"""
        frameworks = set()

        # Buscar indicadores de frameworks en archivos de configuraci√≥n
        config_files = {
            "package.json": ["react", "vue", "angular", "express", "next", "nuxt"],
            "requirements.txt": ["django", "flask", "fastapi", "pyramid"],
            "Gemfile": ["rails", "sinatra"],
            "composer.json": ["laravel", "symfony", "codeigniter"],
            "pom.xml": ["spring", "struts", "hibernate"],
            "build.gradle": ["spring", "android"],
        }

        for config_file, framework_list in config_files.items():
            config_path = root / config_file
            if config_path.exists():
                try:
                    content = config_path.read_text(encoding="utf-8").lower()
                    for framework in framework_list:
                        if framework in content:
                            frameworks.add(framework)
                except (PermissionError, OSError, UnicodeDecodeError):
                    continue

        # NUEVO v5.3: Si no hay frameworks detectados en configs, buscar en archivos individuales
        if not frameworks:
            try:
                sample_files = (
                    list(root.rglob("*.tsx"))[:3]
                    + list(root.rglob("*.jsx"))[:3]
                    + list(root.rglob("*.ts"))[:3]
                )
                for file_path in sample_files:
                    if file_path.is_file():
                        content = file_path.read_text(encoding="utf-8").lower()
                        if (
                            "react" in content
                            or "usestate" in content
                            or "useeffect" in content
                        ):
                            frameworks.add("react")
                        if "vue" in content or "@vue" in content:
                            frameworks.add("vue")
                        if "angular" in content or "@angular" in content:
                            frameworks.add("angular")
                        break  # Solo analizar primer archivo encontrado
            except (PermissionError, OSError, UnicodeDecodeError):
                pass

        return list(frameworks)

    def resolve_file_path(self, file_path: str) -> str:
        """Resolver ruta de archivo con contexto del proyecto"""
        try:
            if not os.path.isabs(file_path):
                return os.path.abspath(file_path)
            return file_path
        except Exception:
            return file_path

    def get_project_root(self) -> str:
        """Obtener directorio ra√≠z del proyecto"""
        return self.project_root

    def analyze_project_structure(self) -> Dict[str, Any]:
        """Analizar estructura del proyecto"""
        return self.structure


class IntegrityChecker:
    """Verificador de integridad de c√≥digo universal"""

    def __init__(self, file_path: str, project_context):
        self.file_path = file_path
        self.project_context = project_context
        self.file_type = self._detect_file_type()

    def _detect_file_type(self) -> str:
        """Detectar tipo de archivo para verificaci√≥n"""
        ext = os.path.splitext(self.file_path)[1].lower()
        type_mapping = {
            ".py": "python",
            ".js": "javascript",
            ".jsx": "javascript",
            ".ts": "typescript",
            ".tsx": "typescript",
            ".java": "java",
            ".json": "json",
            ".yaml": "yaml",
            ".yml": "yaml",
        }
        return type_mapping.get(ext, "generic")

    def pre_modification_check(
        self, operation: str, pattern: str, content: str
    ) -> Dict[str, Any]:
        """Verificaci√≥n antes de modificar"""
        checks = {
            "syntax_valid": True,
            "dependencies_intact": True,
            "imports_valid": True,
            "references_safe": True,
            "warnings": [],
            "errors": [],
        }

        # 1. Verificar sintaxis actual
        if self.file_type == "python":
            checks.update(self._check_python_syntax())
        elif self.file_type in ["javascript", "typescript"]:
            checks.update(self._check_js_syntax())
        elif self.file_type == "java":
            checks.update(self._check_java_syntax())
        elif self.file_type == "json":
            checks.update(self._check_json_syntax())

        # 2. Analizar impacto del cambio
        impact_analysis = self._analyze_change_impact(operation, pattern, content)
        checks["impact_analysis"] = impact_analysis

        # 3. Verificar dependencias
        dependency_check = self._check_dependencies()
        checks.update(dependency_check)

        return checks

    def post_modification_check(self) -> Dict[str, Any]:
        """Verificaci√≥n despu√©s de modificar"""
        checks = {
            "syntax_valid": True,
            "compilation_ok": True,
            "imports_resolved": True,
            "tests_pass": None,
            "warnings": [],
            "errors": [],
        }

        # 1. Verificar sintaxis del archivo modificado
        if self.file_type == "python":
            checks.update(self._check_python_syntax())
        elif self.file_type in ["javascript", "typescript"]:
            checks.update(self._check_js_syntax())
        elif self.file_type == "java":
            checks.update(self._check_java_compilation())

        # 2. Verificar que imports siguen funcionando
        if self.file_type == "python":
            checks.update(self._check_python_imports())

        # 3. Ejecutar tests si existen
        test_result = self._run_related_tests()
        checks["tests_pass"] = test_result

        return checks

    def _check_python_syntax(self) -> Dict[str, Any]:
        """Verificar sintaxis Python"""
        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                source = f.read()

            # Compilar para verificar sintaxis
            compile(source, self.file_path, "exec")

            # Verificar AST
            tree = ast.parse(source)

            return {"syntax_valid": True, "ast_valid": True}
        except SyntaxError as e:
            return {"syntax_valid": False, "errors": [f"Error de sintaxis Python: {e}"]}
        except Exception as e:
            return {"syntax_valid": False, "errors": [f"Error procesando Python: {e}"]}

    def _check_js_syntax(self) -> Dict[str, Any]:
        """Verificar sintaxis JavaScript/TypeScript"""
        try:
            # Intentar usar node para verificar sintaxis
            result = subprocess.run(
                ["node", "-c", self.file_path],
                capture_output=True,
                text=True,
                timeout=5,
            )

            if result.returncode == 0:
                return {"syntax_valid": True}
            else:
                return {
                    "syntax_valid": False,
                    "errors": [f"Error sintaxis JS: {result.stderr}"],
                }
        except (subprocess.TimeoutExpired, FileNotFoundError):
            # Si no hay node, verificaci√≥n b√°sica
            return self._basic_js_syntax_check()

    def _basic_js_syntax_check(self) -> Dict[str, Any]:
        """Verificaci√≥n b√°sica de sintaxis JS sin node"""
        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # Verificaciones b√°sicas
            bracket_pairs = {"{": "}", "[": "]", "(": ")"}
            stack = []

            for char in content:
                if char in bracket_pairs:
                    stack.append(bracket_pairs[char])
                elif char in bracket_pairs.values():
                    if not stack or stack.pop() != char:
                        return {
                            "syntax_valid": False,
                            "errors": ["Par√©ntesis/brackets desbalanceados"],
                        }

            if stack:
                return {
                    "syntax_valid": False,
                    "errors": ["Par√©ntesis/brackets no cerrados"],
                }

            return {"syntax_valid": True}

        except Exception as e:
            return {"syntax_valid": False, "errors": [f"Error verificando JS: {e}"]}

    def _check_java_syntax(self) -> Dict[str, Any]:
        """Verificar sintaxis Java b√°sica"""
        # Para Java, hacer verificaci√≥n b√°sica sin compilar
        return self._basic_java_syntax_check()

    def _basic_java_syntax_check(self) -> Dict[str, Any]:
        """Verificaci√≥n b√°sica Java"""
        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # Verificaciones b√°sicas Java
            if content.count("{") != content.count("}"):
                return {
                    "syntax_valid": False,
                    "errors": ["Llaves desbalanceadas en Java"],
                }

            if content.count("(") != content.count(")"):
                return {
                    "syntax_valid": False,
                    "errors": ["Par√©ntesis desbalanceados en Java"],
                }

            return {"syntax_valid": True}

        except Exception as e:
            return {"syntax_valid": False, "errors": [f"Error verificando Java: {e}"]}

    def _check_java_compilation(self) -> Dict[str, Any]:
        """Verificar compilaci√≥n Java"""
        try:
            result = subprocess.run(
                ["javac", "-cp", ".", self.file_path],
                capture_output=True,
                text=True,
                timeout=10,
            )

            if result.returncode == 0:
                return {"compilation_ok": True}
            else:
                return {
                    "compilation_ok": False,
                    "errors": [f"Error compilaci√≥n Java: {result.stderr}"],
                }
        except (subprocess.TimeoutExpired, FileNotFoundError):
            return {
                "compilation_ok": False,
                "warnings": [
                    "No se pudo verificar compilaci√≥n Java (javac no disponible)"
                ],
            }

    def _check_json_syntax(self) -> Dict[str, Any]:
        """Verificar sintaxis JSON"""
        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                json.load(f)
            return {"syntax_valid": True}
        except json.JSONDecodeError as e:
            return {"syntax_valid": False, "errors": [f"JSON inv√°lido: {e}"]}

    def _check_python_imports(self) -> Dict[str, Any]:
        """Verificar que imports Python funcionan"""
        try:
            # Cambiar al directorio del proyecto para imports relativos
            original_dir = os.getcwd()
            os.chdir(self.project_context.project_root)

            result = subprocess.run(
                ["python", "-m", "py_compile", self.file_path],
                capture_output=True,
                text=True,
                timeout=5,
            )

            os.chdir(original_dir)

            if result.returncode == 0:
                return {"imports_resolved": True}
            else:
                return {
                    "imports_resolved": False,
                    "errors": [f"Error imports: {result.stderr}"],
                }
        except Exception as e:
            return {
                "imports_resolved": False,
                "warnings": [f"No se pudo verificar imports: {e}"],
            }

    def _analyze_change_impact(
        self, operation: str, pattern: str, content: str
    ) -> Dict[str, Any]:
        """Analizar impacto del cambio"""
        impact = {"risk_level": "low", "affected_areas": [], "recommendations": []}

        # Analizar qu√© tipo de cambio es
        if self.file_type == "python":
            if any(keyword in pattern for keyword in ["class ", "def ", "import "]):
                impact["risk_level"] = "high"
                impact["affected_areas"].append("Definiciones principales")
                impact["recommendations"].append("Ejecutar tests relacionados")

            if "from " in content or "import " in content:
                impact["risk_level"] = "medium"
                impact["affected_areas"].append("Dependencias")

        elif self.file_type in ["javascript", "typescript"]:
            if any(
                keyword in pattern
                for keyword in ["export", "import", "function", "class"]
            ):
                impact["risk_level"] = "high"
                impact["affected_areas"].append("Exports/Imports")
                impact["recommendations"].append("Verificar dependencias")

        elif self.file_type == "json":
            if operation == "replace" and any(
                key in pattern for key in ["dependencies", "scripts", "main"]
            ):
                impact["risk_level"] = "high"
                impact["affected_areas"].append("Configuraci√≥n cr√≠tica")

        return impact

    def _check_dependencies(self) -> Dict[str, Any]:
        """Verificar dependencias del proyecto"""
        deps = {"dependencies_intact": True, "missing_deps": [], "warnings": []}

        # Para Python, verificar requirements.txt o pyproject.toml
        if self.file_type == "python":
            req_file = os.path.join(
                self.project_context.project_root, "requirements.txt"
            )
            if os.path.exists(req_file):
                deps.update(self._check_python_requirements(req_file))

        # Para JS/TS, verificar package.json
        elif self.file_type in ["javascript", "typescript"]:
            pkg_file = os.path.join(self.project_context.project_root, "package.json")
            if os.path.exists(pkg_file):
                deps.update(self._check_npm_dependencies(pkg_file))

        return deps

    def _check_python_requirements(self, req_file: str) -> Dict[str, Any]:
        """Verificar requirements de Python"""
        try:
            result = subprocess.run(
                ["pip", "check"], capture_output=True, text=True, timeout=10
            )

            if result.returncode == 0:
                return {"dependencies_intact": True}
            else:
                return {
                    "dependencies_intact": False,
                    "missing_deps": result.stdout.split("\n"),
                }
        except Exception:
            return {"warnings": ["No se pudo verificar dependencias Python"]}

    def _check_npm_dependencies(self, pkg_file: str) -> Dict[str, Any]:
        """Verificar dependencias npm"""
        try:
            os.chdir(self.project_context.project_root)
            result = subprocess.run(
                ["npm", "ls", "--depth=0"], capture_output=True, text=True, timeout=15
            )

            if "UNMET DEPENDENCY" in result.stdout:
                return {
                    "dependencies_intact": False,
                    "missing_deps": ["Dependencias npm faltantes"],
                }
            else:
                return {"dependencies_intact": True}
        except Exception:
            return {"warnings": ["No se pudo verificar dependencias npm"]}

    def _run_related_tests(self) -> Optional[bool]:
        """Ejecutar tests relacionados al archivo"""
        try:
            # Para Python con pytest
            if self.file_type == "python":
                test_file = self._find_test_file()
                if test_file:
                    result = subprocess.run(
                        ["pytest", test_file, "-v"],
                        capture_output=True,
                        text=True,
                        timeout=30,
                    )
                    return result.returncode == 0

            # Para JS/TS con npm test
            elif self.file_type in ["javascript", "typescript"]:
                if os.path.exists(
                    os.path.join(self.project_context.project_root, "package.json")
                ):
                    result = subprocess.run(
                        ["npm", "test", "--", "--passWithNoTests"],
                        capture_output=True,
                        text=True,
                        timeout=60,
                    )
                    return result.returncode == 0

        except Exception:
            pass

        return None

    def _find_test_file(self) -> Optional[str]:
        """Encontrar archivo de test relacionado"""
        base_name = os.path.splitext(os.path.basename(self.file_path))[0]

        # Posibles ubicaciones de tests
        test_patterns = [
            f"test_{base_name}.py",
            f"{base_name}_test.py",
            f"tests/test_{base_name}.py",
            f"tests/{base_name}_test.py",
        ]

        for pattern in test_patterns:
            test_path = os.path.join(self.project_context.project_root, pattern)
            if os.path.exists(test_path):
                return test_path

        return None


class EnhancedSurgicalModifier:
    """Modificador quir√∫rgico con verificaci√≥n de integridad completa"""

    def __init__(self, verbose=False, confirm=True, keep_backups=False):
        self.verbose = verbose
        self.confirm = confirm
        self.keep_backups = keep_backups
        self.backup_manager = BackupManager(keep_successful_backups=keep_backups)
        self.project_context = ProjectContext()

    def execute_with_integrity_check(
        self, operation: str, file_path: str, pattern: str, content: str
    ) -> Dict[str, Any]:
        """Ejecutar operaci√≥n con verificaci√≥n completa de integridad"""
        
        resolved_path = self.project_context.resolve_file_path(file_path)
        
        # Crear checker de integridad
        integrity_checker = IntegrityChecker(resolved_path, self.project_context)
        
        result = {
            "success": False,
            "operation": operation,
            "file_path": resolved_path,
            "message": "",
            "integrity_warnings": [],
            "details": []
        }

        try:
            # 1. VERIFICACI√ìN PRE-MODIFICACI√ìN
            if self.verbose:
                ColorLogger.section("VERIFICACI√ìN PRE-MODIFICACI√ìN")
            
            pre_checks = integrity_checker.pre_modification_check(operation, pattern, content)
            
            if pre_checks.get("errors"):
                result["success"] = False
                result["message"] = "Errores en verificaci√≥n previa"
                result["details"] = pre_checks["errors"]
                return result
            
            if pre_checks.get("warnings"):
                result["integrity_warnings"].extend(pre_checks["warnings"])

            # 2. CREAR BACKUP
            backup_path = None
            if os.path.exists(resolved_path):
                backup_path = self.backup_manager.create_backup(resolved_path, ".backup")
                result["backup_path"] = backup_path

            # 3. EJECUTAR MODIFICACI√ìN
            base_modifier = SurgicalModifierUltimate(
                verbose=self.verbose, 
                confirm=self.confirm, 
                keep_backups=self.keep_backups
            )
            
            modification_result = base_modifier.execute(operation, resolved_path, pattern, content)
            
            if not modification_result["success"]:
                # Restaurar backup si fall√≥ la modificaci√≥n
                if backup_path:
                    self.backup_manager.restore_from_backup(backup_path, resolved_path)
                
                result["success"] = False
                result["message"] = modification_result["message"]
                return result

            # 4. VERIFICACI√ìN POST-MODIFICACI√ìN
            if self.verbose:
                ColorLogger.section("VERIFICACI√ìN POST-MODIFICACI√ìN")
            
            post_checks = integrity_checker.post_modification_check()
            
            if post_checks.get("errors"):
                # Restaurar backup por errores de integridad
                if backup_path:
                    self.backup_manager.restore_from_backup(backup_path, resolved_path)
                
                result["success"] = False
                result["message"] = "Errores en verificaci√≥n posterior - archivo restaurado"
                result["details"] = post_checks["errors"]
                return result
            
            if post_checks.get("warnings"):
                result["integrity_warnings"].extend(post_checks["warnings"])

            # 5. VERIFICAR TESTS SI EST√ÅN DISPONIBLES
            if post_checks.get("tests_pass") is not None:
                if post_checks["tests_pass"]:
                    result["details"].append("Tests relacionados: PASAN")
                else:
                    result["integrity_warnings"].append("Tests relacionados: FALLAN")

            # 6. OPERACI√ìN EXITOSA
            result["success"] = True
            result["message"] = "Operaci√≥n completada con verificaci√≥n de integridad"
            
            # Limpiar backups si todo sali√≥ bien
            if not self.keep_backups:
                self.backup_manager.cleanup_successful_backups()
                result["backups_cleaned"] = True

            return result

        except Exception as e:
            # Error inesperado - restaurar backup
            if backup_path and os.path.exists(backup_path):
                self.backup_manager.restore_from_backup(backup_path, resolved_path)
            
            result["success"] = False
            result["message"] = f"Error inesperado: {str(e)}"
            return result


class SurgicalModifierUltimate:
    """Clase principal para operaciones de modificaci√≥n quir√∫rgica de archivos"""
    
    def __init__(self, verbose=False, confirm=True, explore=False, keep_backups=False, check_integrity=False):
        """Inicializar componentes b√°sicos"""
        self.verbose = verbose
        self.confirm = confirm
        self.explore = explore
        self.keep_backups = keep_backups
        self.check_integrity = check_integrity
        self.backup_manager = BackupManager(keep_successful_backups=keep_backups, max_backups=5)
        self.project_context = ProjectContext()
    
    def execute(self, operation: str, file_path: str, pattern: str = "", content: str = "", auto_backup: bool = True) -> Dict[str, Any]:
        """M√©todo principal que ejecuta operaciones"""
        try:
            resolved_path = self.project_context.resolve_file_path(file_path)
            
            if operation == "create":
                success = self.create(resolved_path, content, auto_backup)
            elif operation == "replace":
                success = self.replace(resolved_path, pattern, content, auto_backup)
            elif operation == "after":
                success = self.after(resolved_path, pattern, content, auto_backup)
            elif operation == "before":
                success = self.before(resolved_path, pattern, content, auto_backup)
            elif operation == "append":
                success = self.append(resolved_path, content, auto_backup)
            elif operation == "split":
                success = self.split(resolved_path, pattern, auto_backup)
            elif operation == "extract":
                success = self.extract(resolved_path, pattern, content, auto_backup)
            else:
                if self.verbose:
                    ColorLogger.error(f"Operaci√≥n no soportada: {operation}")
                success = False
            
            return {
                "success": success,
                "operation": operation,
                "file_path": resolved_path,
                "message": "Operation completed successfully" if success else "Operation failed",
                "context": self.project_context.context,
                "project_type": self.project_context.structure.get("project_type", "unknown")
            }
        except Exception as e:
            return {
                "success": False,
                "operation": operation,
                "file_path": file_path,
                "message": f"Error: {str(e)}",
                "error": str(e)
            }
    
    def create(self, file_path: str, content: str = "", auto_backup: bool = True) -> bool:
        """Crear archivo nuevo con directorios autom√°ticos"""
        try:
            # Crear directorios padre si no existen
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # Backup si el archivo existe y auto_backup est√° habilitado
            if os.path.exists(file_path) and auto_backup:
                backup_path = self.backup_manager.create_backup(file_path, ".backup")
                if self.verbose:
                    ColorLogger.info(f"Backup creado: {backup_path}")
            
            # Procesar contenido usando ContentHandler
            content_handler = ContentHandler(content, file_path, "create")
            safe_content, temp_file = content_handler.get_safe_content()
            
            # Escribir contenido al archivo
            if temp_file:
                # Usar archivo temporal
                shutil.copy2(temp_file, file_path)
                os.unlink(temp_file)  # Limpiar archivo temporal
            else:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(safe_content)
            
            if self.verbose:
                ColorLogger.success(f"Archivo creado: {file_path}")
            
            return True
            
        except Exception as e:
            if self.verbose:
                ColorLogger.error(f"Error creando archivo {file_path}: {str(e)}")
            return False

    def replace(self, file_path: str, pattern: str, content: str, auto_backup: bool = True) -> bool:
        """Reemplazar contenido existente"""
        try:
            if not os.path.exists(file_path):
                if self.verbose:
                    ColorLogger.error(f"Archivo no encontrado: {file_path}")
                return False
            
            # Leer contenido actual
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            # Crear backup si est√° habilitado
            if auto_backup:
                backup_path = self.backup_manager.create_backup(file_path, ".backup")
                if self.verbose:
                    ColorLogger.info(f"Backup creado: {backup_path}")
            
            # Buscar patr√≥n
            if pattern not in original_content:
                # Usar b√∫squeda flexible
                helper = UniversalPatternHelper(original_content, file_path)
                similar_patterns = helper.find_flexible_pattern(pattern, 0.6)
                
                if similar_patterns:
                    if self.verbose:
                        ColorLogger.warning(f"Patr√≥n exacto no encontrado. Sugerencias:")
                        for match in similar_patterns[:3]:
                            ColorLogger.info(f"  L√≠nea {match['line_number']}: {match['content']}")
                return False
            
            # Procesar nuevo contenido
            content_handler = ContentHandler(content, file_path, "replace")
            safe_content, temp_file = content_handler.get_safe_content()
            
            # Realizar reemplazo
            if temp_file:
                # Leer contenido del archivo temporal
                with open(temp_file, 'r', encoding='utf-8') as f:
                    new_content = f.read()
                os.unlink(temp_file)
            else:
                new_content = safe_content
            
            updated_content = original_content.replace(pattern, new_content)
            
            # Escribir archivo actualizado
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)
            
            if self.verbose:
                ColorLogger.success(f"Contenido reemplazado en: {file_path}")
                ColorLogger.diff("CAMBIO REALIZADO", pattern, new_content)
            
            return True
            
        except Exception as e:
            if self.verbose:
                ColorLogger.error(f"Error reemplazando en {file_path}: {str(e)}")
            return False

    def after(self, file_path: str, pattern: str, content: str, auto_backup: bool = True) -> bool:
        """Insertar despu√©s de patr√≥n"""
        try:
            if not os.path.exists(file_path):
                if self.verbose:
                    ColorLogger.error(f"Archivo no encontrado: {file_path}")
                return False
            
            # Leer contenido actual
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Crear backup si est√° habilitado
            if auto_backup:
                backup_path = self.backup_manager.create_backup(file_path, ".backup")
                if self.verbose:
                    ColorLogger.info(f"Backup creado: {backup_path}")
            
            # Buscar l√≠nea con patr√≥n
            pattern_line_index = None
            for i, line in enumerate(lines):
                if pattern in line:
                    pattern_line_index = i
                    break
            
            if pattern_line_index is None:
                if self.verbose:
                    ColorLogger.error(f"Patr√≥n no encontrado: {pattern}")
                return False
            
            # Procesar nuevo contenido
            content_handler = ContentHandler(content, file_path, "after")
            safe_content, temp_file = content_handler.get_safe_content()
            
            if temp_file:
                with open(temp_file, 'r', encoding='utf-8') as f:
                    new_content = f.read()
                os.unlink(temp_file)
            else:
                new_content = safe_content
            
            # Insertar despu√©s del patr√≥n
            lines.insert(pattern_line_index + 1, new_content + '\n')
            
            # Escribir archivo actualizado
            with open(file_path, 'w', encoding='utf-8') as f:
                f.writelines(lines)
            
            if self.verbose:
                ColorLogger.success(f"Contenido insertado despu√©s de la l√≠nea {pattern_line_index + 1}")
            
            return True
            
        except Exception as e:
            if self.verbose:
                ColorLogger.error(f"Error insertando despu√©s en {file_path}: {str(e)}")
            return False

    def before(self, file_path: str, pattern: str, content: str, auto_backup: bool = True) -> bool:
        """Insertar antes de patr√≥n"""
        try:
            if not os.path.exists(file_path):
                if self.verbose:
                    ColorLogger.error(f"Archivo no encontrado: {file_path}")
                return False
            
            # Leer contenido actual
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Crear backup si est√° habilitado
            if auto_backup:
                backup_path = self.backup_manager.create_backup(file_path, ".backup")
                if self.verbose:
                    ColorLogger.info(f"Backup creado: {backup_path}")
            
            # Buscar l√≠nea con patr√≥n
            pattern_line_index = None
            for i, line in enumerate(lines):
                if pattern in line:
                    pattern_line_index = i
                    break
            
            if pattern_line_index is None:
                if self.verbose:
                    ColorLogger.error(f"Patr√≥n no encontrado: {pattern}")
                return False
            
            # Procesar nuevo contenido
            content_handler = ContentHandler(content, file_path, "before")
            safe_content, temp_file = content_handler.get_safe_content()
            
            if temp_file:
                with open(temp_file, 'r', encoding='utf-8') as f:
                    new_content = f.read()
                os.unlink(temp_file)
            else:
                new_content = safe_content
            
            # Insertar antes del patr√≥n
            lines.insert(pattern_line_index, new_content + '\n')
            
            # Escribir archivo actualizado
            with open(file_path, 'w', encoding='utf-8') as f:
                f.writelines(lines)
            
            if self.verbose:
                ColorLogger.success(f"Contenido insertado antes de la l√≠nea {pattern_line_index + 1}")
            
            return True
            
        except Exception as e:
            if self.verbose:
                ColorLogger.error(f"Error insertando antes en {file_path}: {str(e)}")
            return False

    def append(self, file_path: str, content: str, auto_backup: bool = True) -> bool:
        """Agregar al final del archivo"""
        try:
            # Crear archivo si no existe
            if not os.path.exists(file_path):
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write("")
            
            # Crear backup si est√° habilitado
            if auto_backup:
                backup_path = self.backup_manager.create_backup(file_path, ".backup")
                if self.verbose:
                    ColorLogger.info(f"Backup creado: {backup_path}")
            
            # Procesar contenido
            content_handler = ContentHandler(content, file_path, "append")
            safe_content, temp_file = content_handler.get_safe_content()
            
            if temp_file:
                with open(temp_file, 'r', encoding='utf-8') as f:
                    new_content = f.read()
                os.unlink(temp_file)
            else:
                new_content = safe_content
            
            # Agregar al final
            with open(file_path, 'a', encoding='utf-8') as f:
                f.write('\n' + new_content)
            
            if self.verbose:
                ColorLogger.success(f"Contenido agregado al final de: {file_path}")
            
            return True
            
        except Exception as e:
            if self.verbose:
                ColorLogger.error(f"Error agregando al final de {file_path}: {str(e)}")
            return False

    def split(self, file_path: str, pattern: str, auto_backup: bool = True) -> bool:
        """Dividir l√≠neas pegadas"""
        try:
            if not os.path.exists(file_path):
                if self.verbose:
                    ColorLogger.error(f"Archivo no encontrado: {file_path}")
                return False
            
            # Leer contenido actual
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Crear backup si est√° habilitado
            if auto_backup:
                backup_path = self.backup_manager.create_backup(file_path, ".backup")
                if self.verbose:
                    ColorLogger.info(f"Backup creado: {backup_path}")
            
            # Dividir l√≠neas seg√∫n el patr√≥n
            if pattern in content:
                # Reemplazar patr√≥n con patr√≥n + nueva l√≠nea
                updated_content = content.replace(pattern, pattern + '\n')
                
                # Escribir archivo actualizado
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(updated_content)
                
                if self.verbose:
                    ColorLogger.success(f"L√≠neas divididas en: {file_path}")
                
                return True
            else:
                if self.verbose:
                    ColorLogger.error(f"Patr√≥n no encontrado: {pattern}")
                return False
            
        except Exception as e:
            if self.verbose:
                ColorLogger.error(f"Error dividiendo l√≠neas en {file_path}: {str(e)}")
            return False

    def extract(self, file_path: str, pattern: str, target_file: str, auto_backup: bool = True) -> bool:
        """Extraer contenido a otro archivo"""
        try:
            if not os.path.exists(file_path):
                if self.verbose:
                    ColorLogger.error(f"Archivo fuente no encontrado: {file_path}")
                return False
            
            # Leer contenido actual
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Buscar contenido que coincida con el patr√≥n
            extracted_lines = []
            for line in lines:
                if pattern in line:
                    extracted_lines.append(line)
            
            if not extracted_lines:
                if self.verbose:
                    ColorLogger.error(f"No se encontr√≥ contenido que coincida con: {pattern}")
                return False
            
            # Crear directorio del archivo destino si no existe
            os.makedirs(os.path.dirname(target_file), exist_ok=True)
            
            # Crear backup del archivo destino si existe
            if os.path.exists(target_file) and auto_backup:
                backup_path = self.backup_manager.create_backup(target_file, ".backup")
                if self.verbose:
                    ColorLogger.info(f"Backup del archivo destino creado: {backup_path}")
            
            # Escribir contenido extra√≠do al archivo destino
            with open(target_file, 'w', encoding='utf-8') as f:
                f.writelines(extracted_lines)
            
            if self.verbose:
                ColorLogger.success(f"Contenido extra√≠do de {file_path} a {target_file}")
                ColorLogger.info(f"Se extrajeron {len(extracted_lines)} l√≠neas")
            
            return True
            
        except Exception as e:
            if self.verbose:
                ColorLogger.error(f"Error extrayendo contenido: {str(e)}")
            return False

    def execute_explore_mode(self, file_path: str, search_term: Optional[str] = None):
        """Ejecutar modo exploraci√≥n"""
        try:
            resolved_path = self.project_context.resolve_file_path(file_path)
            
            if not os.path.exists(resolved_path):
                ColorLogger.error(f"Archivo no encontrado: {resolved_path}")
                return
            
            if search_term:
                # B√∫squeda espec√≠fica
                UniversalExplorer.search_in_file(resolved_path, search_term, context_lines=3)
            else:
                # Exploraci√≥n completa del archivo
                UniversalExplorer.show_file_structure(resolved_path, show_lines=True, filter_type="smart")
            
        except Exception as e:
            ColorLogger.error(f"Error en modo exploraci√≥n: {str(e)}")


def show_enhanced_help_v53():
    """Mostrar ayuda mejorada para v5.3"""
    print("""
üîß SURGICAL MODIFIER ULTIMATE v5.3 - HERRAMIENTA UNIVERSAL CORREGIDA

üìã USO:
  python3 surgical_modifier_ultimate.py [opciones] <operaci√≥n> <archivo> <patr√≥n> [contenido]

üõ°Ô∏è OPCIONES:
  --verbose        : Diff visual y an√°lisis detallado
  --confirm        : Confirmaci√≥n antes de ejecutar
  --explore        : Modo exploraci√≥n universal
  --keep-backups   : Conservar backups incluso en operaciones exitosas
  --check-integrity: Verificaci√≥n completa de sintaxis, deps y tests

‚öôÔ∏è OPERACIONES DISPONIBLES:
  CREATE   - Crear archivo nuevo
  REPLACE  - Reemplazar contenido existente  
  AFTER    - Insertar despu√©s de patr√≥n
  BEFORE   - Insertar antes de patr√≥n
  APPEND   - Agregar al final del archivo
  SPLIT    - Dividir l√≠neas pegadas
  EXTRACT  - Extraer contenido a otro archivo

üîç VERIFICACI√ìN DE INTEGRIDAD:
  --check-integrity verifica:
  ‚úÖ Sintaxis v√°lida antes y despu√©s de modificar
  ‚úÖ Dependencias del proyecto intactas
  ‚úÖ Imports resueltos correctamente
  ‚úÖ Tests relacionados (si existen)
  ‚úÖ An√°lisis de impacto del cambio (bajo/medio/alto riesgo)

üåç SOPORTE UNIVERSAL COMPLETO:
  ‚úÖ Python, JavaScript, TypeScript, Java, C++, C#, PHP, Ruby, Go, Rust
  ‚úÖ Frameworks: Django, Flask, React, Vue, Angular, Spring, Express
  ‚úÖ Detecci√≥n autom√°tica de contexto de proyecto
  ‚úÖ Backups inteligentes con limpieza autom√°tica
  ‚úÖ B√∫squeda flexible con sugerencias

üéØ EJEMPLOS:

# Crear archivo nuevo
python3 surgical_modifier_ultimate.py create utils/helpers.py "def helper_function(): pass"

# Reemplazar con verificaci√≥n de integridad
python3 surgical_modifier_ultimate.py --check-integrity replace models.py "old_function" "new_function"

# Explorar archivo antes de modificar
python3 surgical_modifier_ultimate.py --explore models.py "calculate"

# Extraer funci√≥n a otro archivo
python3 surgical_modifier_ultimate.py extract models.py "def calculate_price" utils/pricing.py

¬°HERRAMIENTA UNIVERSAL CORREGIDA Y LISTA PARA USO! üõ°Ô∏è
""")


def main():
    """Funci√≥n principal universal v5.3 con verificaci√≥n de integridad"""

    # Procesar argumentos incluyendo --check-integrity
    args = sys.argv[1:]
    verbose = "--verbose" in args
    confirm = "--confirm" in args
    explore = "--explore" in args
    show_pattern = "--show-pattern" in args
    keep_backups = "--keep-backups" in args
    check_integrity = "--check-integrity" in args

    # Remover flags de argumentos
    args = [arg for arg in args if not arg.startswith("--")]

    if len(args) < 1 or args[0] in ["-h", "--help", "help"]:
        show_enhanced_help_v53()
        sys.exit(0)

    if explore and len(args) >= 1:
        # Modo exploraci√≥n universal
        file_path = args[0]
        search_term = args[1] if len(args) > 1 else None

        modifier = SurgicalModifierUltimate(
            verbose=verbose, confirm=confirm, explore=True, keep_backups=keep_backups
        )
        modifier.execute_explore_mode(file_path, search_term)
        return
    elif show_pattern and len(args) >= 3:
        # C√≥digo de show-pattern existente
        file_path = args[0]
        start_line = int(args[1])
        end_line = int(args[2])

        project_context = ProjectContext()
        resolved_path = project_context.resolve_file_path(file_path)

        if not os.path.exists(resolved_path):
            print(f"‚ùå Archivo no encontrado: {resolved_path}")
            return

        try:
            with open(resolved_path, "r", encoding="utf-8") as f:
                lines = f.readlines()

            print(
                f"üìã SHOW PATTERN: {os.path.basename(resolved_path)} (l√≠neas {start_line}-{end_line})"
            )
            print("=" * 70)

            for i in range(max(0, start_line - 1), min(len(lines), end_line)):
                line_content = lines[i].rstrip()
                print(
                    f"{i+1:4d}: {repr(line_content)}"
                )

            print("=" * 70)
            print(
                f"üìä Caracteres especiales visibles, total l√≠neas en archivo: {len(lines)}"
            )

        except Exception as e:
            print(f"‚ùå Error: {e}")
        return

    if len(args) < 3:
        show_enhanced_help_v53()
        sys.exit(0)

    operation = args[0].lower()
    file_path = args[1]
    pattern = args[2] if len(args) > 2 else ""
    content = args[3] if len(args) > 3 else ""

    # Usar verificador con integridad si se solicita
    if check_integrity:
        modifier = EnhancedSurgicalModifier(
            verbose=verbose, confirm=confirm, keep_backups=keep_backups
        )
        result = modifier.execute_with_integrity_check(
            operation, file_path, pattern, content
        )
    else:
        # Usar modificador normal
        modifier = SurgicalModifierUltimate(
            verbose=verbose, confirm=confirm, keep_backups=keep_backups
        )
        result = modifier.execute(operation, file_path, pattern, content)

    # Mostrar resultado final
    if result["success"]:
        print(f"\nüéâ ‚úÖ √âXITO TOTAL UNIVERSAL v5.3 - {result['message']}")

        if "integrity_warnings" in result and result["integrity_warnings"]:
            print("‚ö†Ô∏è ADVERTENCIAS DE INTEGRIDAD:")
            for warning in result["integrity_warnings"]:
                print(f"   - {warning}")

        if result.get("backups_cleaned"):
            print("üßπ Backups limpiados autom√°ticamente (operaci√≥n exitosa)")
        elif result.get("backup_path"):
            print(f"üì¶ Backup conservado: {os.path.relpath(result['backup_path'])}")

        if "context" in result:
            print(
                f"üéØ Contexto: {result['context']} | Proyecto: {result['project_type']}"
            )
    else:
        print(f"\n‚ùå OPERACI√ìN FALL√ì: {result.get('message', 'Error desconocido')}")
        print("üì¶ Backup conservado para investigaci√≥n de error")
        if "details" in result:
            print("üìã Detalles:")
            for detail in result["details"]:
                print(f"   - {detail}")

    # NO usar exit 1 - preservar entorno
    sys.exit(0)


if __name__ == "__main__":
    main()